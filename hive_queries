create database exercise1;
----------------------------------
 -- STEP 1 ----------------------
 --------------------------------

add jar /tmp/json-serde-1.3.8-jar-with-dependencies.jar;
drop table if exists exercise1.twitter_data_temp;
CREATE   TABLE exercise1.twitter_data_temp (
    `user` struct< 
    userlocation : String,
    id : BigInt,
    name : String,
    screenname : String,
    geoenabled : boolean>  ,
    tweetmessage String,
    createddate String,
    geolocation String 
)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe' 
WITH SERDEPROPERTIES 
( "ignore.malformed.json" = "false",
  "explicit.null" = "true") 
  STORED AS TEXTFILE 
  location "/hdfs_data/ex1_twitter_raw"  ;
 

select `user`.userlocation ,`user`.id , `user`.name ,`user`.screenname , `user`.geoenabled , tweetmessage  ,
 from_unixtime(unix_timestamp(createddate, "yyyy-MM-dd'T'HH:mm:ss")) as createddate
 , geolocation from exercise1.twitter_data_temp  
 where 
 (`user`.userlocation is not null and 
  `user`.id is not null and   
  `user`.name is not null and 
  `user`.screenname  is not null  );


----------------------------------
 -- STEP 2 ----------------------
 --------------------------------
drop table if exists exercise1.twitter_data_orc; 
CREATE EXTERNAL TABLE exercise1.twitter_data_orc ( 
     userlocation  String,
     id  BigInt, 
     name  String, 
     geoenabled  boolean, 
      tweetmessage String, 
      createddate timestamp, 
      geolocation String ) 
PARTITIONED BY ( screenname  String ) 
STORED AS ORC 
location "/hdfs_data/ex1_twitter_orc"; 


----------------------------------
 -- STEP 3 ----------------------
 --------------------------------
set hive.exec.dynamic.partition=true;  
set hive.exec.dynamic.partition.mode=nonstrict; 
add jar /tmp/json-serde-1.3.8-jar-with-dependencies.jar; 


INSERT INTO TABLE exercise1.twitter_data_orc PARTITION (screenname)
   select `user`.userlocation as userlocation ,`user`.id as id , `user`.name  as name, `user`.geoenabled ,
   tweetmessage , from_unixtime(unix_timestamp(createddate, "yyyy-MM-dd'T'HH:mm:ss")) as createddate , 
   geolocation , `user`.screenname as screenname 
   from exercise1.twitter_data_temp 
   where (`user`.userlocation is not null and  `user`.id is not null and `user`.name is not null and `user`.screenname is not null ) ;




----------------------------------
 -- MISC - For testing -----------
 ---------------------------------  

set hive.exec.dynamic.partition.mode=nonstrict;

INSERT INTO twitter_data_orc partition (screenname)
 VALUES ( 'Cinderford Gloucestershire',	
		 230231618	, 
		 'Aimee',	
		 'Aimee_Cottle'	,
		 true	,
		 'Gastroenteritis has pretty much killed me this week :( off work for a few days whilst I recover!', 
		 '2013-06-20 12:08:14',
		 null);

http://congiu.net/hive-json-serde/1.3.6/hdp23/






-----------
----- Exercise 2 -----
---------------------

drop table if exists exercise2.trump_tweet_sentiments;
CREATE EXTERNAL TABLE exercise2.trump_tweet_sentiments ( 
    time String,
    line String ) 
    PARTITIONED by (sentiment String) 
  stored as orc
 location "/hdfs_data/ex2_trump_tweet_sentiments";
-- 	PARTITIONED by (sentiment String) 


%sql
select  sentiment, count(*) as count
from exercise2.trump_tweet_sentiments
--  where FROM_UNIXTIME(cast(time as BIGINT) DIV 1000) >   CAST(TO_DATE(FROM_UNIXTIME(UNIX_TIMESTAMP()-86400))as date)
-- where FROM_UNIXTIME(cast(time as BIGINT) DIV 1000) >   CAST(TO_DATE(FROM_UNIXTIME(UNIX_TIMESTAMP()-300))as date) -- 5 mins or 24 hours
group by sentiment




-- query to show what haened in the last 5 minutes
select FROM_UNIXTIME(cast(time as BIGINT) DIV 1000) ,FROM_UNIXTIME(UNIX_TIMESTAMP()-300), FROM_UNIXTIME(UNIX_TIMESTAMP())  
from exercise2.live_tweets_pop_hashtags 
 limit 2;



drop table if exists exercise2.live_tweets_hashtags_bucket;
CREATE EXTERNAL TABLE exercise2 .live_tweets_hashtags_bucket(
    time String, 
    hashtag String,
    tweet String)
PARTITIONED BY (hashashtag string )
CLUSTERED BY (time) SORTED BY (time) INTO 20 BUCKETS
stored as orc
location "/hdfs_data/ex2_live_tweets_raw_hashtags_buckets";



CREATE EXTERNAL TABLE live_tweets ( mllis:bigint , tweet  	string, count  	int ) location "/hdfs_data/live_tweets";


===========
step 4
==========

drop table if exists exercise1.CRAZY_DATA_AVRO ;
CREATE TABLE exercise1.CRAZY_DATA_AVRO 
stored as avro
TBLPROPERTIES ('avro.schema.url'='hdfs:///hdfs_data/hive/avro_schema/custom_twitter_avro.avsc')  ;

insert into exercise1.CRAZY_DATA_AVRO 
select named_struct('userlocation',`user`.userlocation,'id',`user`.id,'name',`user`.name,'screenname',`user`.screenname,'geoenabled',`user`.geoenabled,'dummy',1) ,
tweetmessage, createddate, geolocation from exercise1.twitter_data_temp 
   where (`user`.userlocation is not null and  `user`.id is not null and `user`.name is not null and `user`.screenname is not null ) ;
;


jdbc:hive2://ip-10-0-231-204.ec2.internal:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2


INSERT INTO TABLE exercise1.CRAZY_DATA_AVRO select `user`('userlocation',userlocation,'id',id,'name',name,'screenname',screenname,'geoenabled',geoenabled)  ,  tweetmessage , createddate , geolocation  from exercise1.twitter_data_temp;


----- WORKS
insert into CRAZY_DATA_AVRO select named_struct('userlocation','Tor','id',1L,'name',"Jaggi",'screenname',"oye",'geoenabled',true,'dummy',1), "tweet msg", "","" from twitter_data_orc limit 1;
insert into exercise1.CRAZY_DATA_AVRO select named_struct('userlocation',`user`.userlocation,'id',`user`.id,'name',`user`.name,'screenname',`user`.screenname,'geoenabled',`user`.geoenabled,'dummy',1) ,tweetmessage, createddate, geolocation from exercise1.twitter_data_temp ;
---- WORKS


insert into CRAZY_DATA_AVRO select named_struct('userlocation','Tor','id',1L,'name',"Jaggi",'screenname',"oye",'geoenabled',true,'dummy',1), "tweet msg", "","" from twitter_data_orc limit 1;


 set textinputformat.record.delimiter='\n\n';

insert into exercise1.CRAZY_DATA_AVRO select named_struct('userlocation',`user`.userlocation,'id',`user`.id,'name',`user`.name,'screenname', `user`.screenname,'geoenabled',`user`.geoenabled,'dummy',1) ,tweetmessage, createddate, geolocation from exercise1.twitter_data_temp ;
